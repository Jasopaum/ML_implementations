{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = np.concatenate((X_train, X_test)) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    \n",
    "    def __init__(self, dim_latent):\n",
    "        self.dim_latent = dim_latent\n",
    "        \n",
    "    def encode_conv(self, input_image):\n",
    "        with tf.variable_scope(\"encoder\"):\n",
    "            x = tf.keras.layers.Conv2D(filters=32,\n",
    "                                       kernel_size=(4,4),\n",
    "                                       strides=(2,2),\n",
    "                                       padding=\"valid\",\n",
    "                                       activation=tf.nn.relu,\n",
    "                                       name=\"conv1\")(input_image)\n",
    "            x = tf.keras.layers.Conv2D(filters=64,\n",
    "                                       kernel_size=(2,2),\n",
    "                                       strides=(2,2),\n",
    "                                       padding=\"valid\",\n",
    "                                       activation=tf.nn.relu,\n",
    "                                       name=\"conv2\")(x)\n",
    "            x = tf.keras.layers.Conv2D(filters=64,\n",
    "                                       kernel_size=(3,3),\n",
    "                                       strides=(1,1),\n",
    "                                       padding=\"valid\",\n",
    "                                       activation=tf.nn.relu,\n",
    "                                       name=\"conv3\")(x)\n",
    "\n",
    "            flat = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "            mean = tf.keras.layers.Dense(units=self.dim_latent,\n",
    "                                         name=\"mean\")(flat)\n",
    "            std = tf.keras.layers.Dense(units=self.dim_latent,\n",
    "                                        name=\"std\")(flat)\n",
    "            \n",
    "            sample_normal = tf.random_normal(tf.shape(std))\n",
    "            \n",
    "            sample_latent = mean + std * sample_normal\n",
    "            \n",
    "            return sample_latent, mean, std\n",
    "        \n",
    "    def encode_mlp(self, input_image):\n",
    "        with tf.variable_scope(\"encoder\"):\n",
    "            flat = tf.keras.layers.Flatten()(input_image)\n",
    "\n",
    "            \n",
    "            x = tf.keras.layers.Dense(units=256,\n",
    "                                      activation=tf.nn.relu,\n",
    "                                      name=\"fc_encoder1\")(flat)\n",
    "            \n",
    "            mean = tf.keras.layers.Dense(units=self.dim_latent,\n",
    "                                         name=\"mean\")(x)\n",
    "            log_var = tf.keras.layers.Dense(units=self.dim_latent,\n",
    "                                        name=\"std\")(x)\n",
    "            \n",
    "            sample_normal = tf.random_normal(tf.shape(log_var))\n",
    "            \n",
    "            sample_latent = mean + tf.exp(log_var / 2) * sample_normal\n",
    "            \n",
    "            return sample_latent, mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder:\n",
    "    \n",
    "    def __init__(self, dim_latent):\n",
    "        self.dim_latent = dim_latent\n",
    "        \n",
    "    def decode_conv(self, latent_vector):\n",
    "        with tf.variable_scope(\"decoder\"):\n",
    "            x = tf.keras.layers.Dense(units=16,\n",
    "                                      name=\"fc_decoder\")(latent_vector)\n",
    "            \n",
    "            x = tf.reshape(x, (-1, 4, 4, 1))\n",
    "            \n",
    "            x = tf.keras.layers.Conv2DTranspose(filters=64,\n",
    "                                                kernel_size=(3,3),\n",
    "                                                strides=(1,1),\n",
    "                                                padding=\"valid\",\n",
    "                                                activation=tf.nn.relu,\n",
    "                                                name=\"deconv1\")(x)\n",
    "            x = tf.keras.layers.Conv2DTranspose(filters=64,\n",
    "                                                kernel_size=(2,2),\n",
    "                                                strides=(2,2),\n",
    "                                                padding=\"valid\",\n",
    "                                                activation=tf.nn.relu,\n",
    "                                                name=\"deconv2\")(x)\n",
    "            x = tf.keras.layers.Conv2DTranspose(filters=32,\n",
    "                                                kernel_size=(4,4),\n",
    "                                                strides=(2,2),\n",
    "                                                padding=\"valid\",\n",
    "                                                activation=tf.nn.relu,\n",
    "                                                name=\"deconv3\")(x)\n",
    "\n",
    "            flat = tf.keras.layers.Flatten()(x)\n",
    "            x = tf.keras.layers.Dense(units=28*28,\n",
    "                                      activation=tf.nn.sigmoid,\n",
    "                                      name=\"fc_decoder\")(flat)\n",
    "            reconstruction = tf.reshape(x, (-1, 28, 28, 1))\n",
    "            \n",
    "            return reconstruction\n",
    "        \n",
    "    def decode_mlp(self, latent_vector):\n",
    "        with tf.variable_scope(\"decoder\"):\n",
    "            x = tf.keras.layers.Dense(units=256,\n",
    "                                      activation=tf.nn.relu,\n",
    "                                      name=\"fc_decoder1\")(latent_vector)\n",
    "            \n",
    "            x = tf.keras.layers.Dense(units=28*28,\n",
    "                                      activation=tf.nn.sigmoid,\n",
    "                                      name=\"fc_decoder3\")(x)\n",
    "            reconstruction = tf.reshape(x, (-1, 28, 28, 1))\n",
    "            \n",
    "            return reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE:\n",
    "    def __init__(self, input_im_shape, dim_latent):\n",
    "        # Remove self where not needed\n",
    "        self.input_im_shape = input_im_shape\n",
    "        self.dim_latent = dim_latent\n",
    "        \n",
    "        self.encoder = Encoder(dim_latent)\n",
    "        self.decoder = Decoder(dim_latent)\n",
    "\n",
    "        self.original_image = tf.placeholder(tf.float32, (None, *(self.input_im_shape)), name=\"original_image\")\n",
    "\n",
    "        self.batch_size = tf.placeholder(tf.int64, None, name=\"batch_size\")\n",
    "        self.dataset = tf.data.Dataset.from_tensor_slices(self.original_image).shuffle(10000).batch(self.batch_size).repeat()\n",
    "        self.iterator = self.dataset.make_initializable_iterator()\n",
    "\n",
    "        self.original_image_exp = tf.expand_dims(self.iterator.get_next(), -1)\n",
    "\n",
    "        self.latent_vec, mean, log_var = self.encoder.encode_mlp(self.original_image_exp)\n",
    "\n",
    "        self.reconstruction = self.decoder.decode_mlp(self.latent_vec)\n",
    "\n",
    "        # Losses\n",
    "#         self.reconstruction_loss = tf.reduce_mean(tf.math.squared_difference(self.reconstruction,\n",
    "#                                                                              self.original_image_exp))\n",
    "        self.reconstruction_loss = tf.reduce_mean(tf.keras.backend.binary_crossentropy(self.original_image_exp,\n",
    "                                                                                       self.reconstruction))\n",
    "            \n",
    "        self.coeff_latent_loss = tf.placeholder(tf.float32, None, name=\"coeff_latent_loss\")\n",
    "        self.latent_loss = 0.5 * tf.reduce_mean(mean ** 2 + tf.exp(log_var) - log_var - 1)\n",
    "            \n",
    "        self.loss = self.reconstruction_loss + self.coeff_latent_loss * self.latent_loss\n",
    "\n",
    "        # Optimization\n",
    "        self.learning_rate = tf.placeholder(tf.float32, None, name=\"learning_rate\")\n",
    "        self.optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        self.train_op = self.optimizer.minimize(self.loss)\n",
    "\n",
    "        # Summaries   \n",
    "        tf.summary.scalar(\"reconstruction_loss\", self.reconstruction_loss)\n",
    "        tf.summary.scalar(\"latent_loss\", self.latent_loss)\n",
    "        tf.summary.scalar(\"loss\", self.loss)\n",
    "        tf.summary.scalar(\"mean\", mean)\n",
    "        tf.summary.scalar(\"log_var\", log_var)\n",
    "        tf.summary.image(\"train_images\", self.original_image_exp, 16)\n",
    "        tf.summary.image(\"reconstructions\", self.reconstruction, 16)\n",
    "        self.merged_summaries = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "    def train(self, X_train, batch_size, nb_steps, learning_rate, sess):\n",
    "        saver = tf.train.Saver()\n",
    "        summary_writer = tf.summary.FileWriter(\"./tensorboard/\", sess.graph)\n",
    "\n",
    "        sess.run(self.iterator.initializer, feed_dict={self.original_image: X_train,\n",
    "                                                       self.batch_size: batch_size})\n",
    "\n",
    "        for step in range(1, nb_steps + 1):\n",
    "            coeff_latent_loss = min(0.15 * step / 100000, 0.15)\n",
    "#             coeff_latent_loss = 0.15\n",
    "            \n",
    "            _, summaries = sess.run([self.train_op, self.merged_summaries],\n",
    "                                    feed_dict={self.learning_rate: learning_rate,\n",
    "                                               self.coeff_latent_loss: coeff_latent_loss})\n",
    "\n",
    "            if step % 5000 == 0:\n",
    "                print(\"Save and write summaries\")\n",
    "                saver.save(sess, \"./model/model.ckpt\")\n",
    "                summary_writer.add_summary(summaries, step)\n",
    "                \n",
    "            if step % 5000 == 0:\n",
    "                latent_samples = np.random.randn((nb_samples, dim_latent))\n",
    "\n",
    "                generated_images = sess.run(vae.reconstruction,\n",
    "                                            feed_dict={vae.latent_vec: latent_samples})\n",
    "                eval_sum = tf.summary.image(\"rec_from_sample_latent\", generated_images, 16)\n",
    "                summary_writer.add_summary(eval_sum, step)\n",
    "        \n",
    "    def restore(self, ckpt_file, sess):\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_shape = (28, 28)\n",
    "dim_latent = 16\n",
    "batch_size = 256\n",
    "learning_rate = 4e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(im_shape, dim_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n",
      "Save and write summaries\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    vae.train(X_train, batch_size, 300000, learning_rate, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey beta1_power_1 not found in checkpoint\n\t [[node save_6/RestoreV2 (defined at <ipython-input-18-009371bbf2b9>:78) ]]\n\t [[node save_6/RestoreV2 (defined at <ipython-input-18-009371bbf2b9>:78) ]]\n\nCaused by op 'save_6/RestoreV2', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/jason/.local/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/jason/.local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/jason/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/jason/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/jason/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/jason/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/jason/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/jason/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/jason/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/jason/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/home/jason/.local/lib/python3.5/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/jason/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/jason/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/jason/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-a0f366644799>\", line 4, in <module>\n    vae.restore(\"./model/model.ckpt\", sess)\n  File \"<ipython-input-18-009371bbf2b9>\", line 78, in restore\n    saver = tf.train.Saver()\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n    self.build()\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 844, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 881, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 332, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 580, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1572, in restore_v2\n    name=name)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey beta1_power_1 not found in checkpoint\n\t [[node save_6/RestoreV2 (defined at <ipython-input-18-009371bbf2b9>:78) ]]\n\t [[node save_6/RestoreV2 (defined at <ipython-input-18-009371bbf2b9>:78) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key beta1_power_1 not found in checkpoint\n\t [[{{node save_6/RestoreV2}}]]\n\t [[{{node save_6/RestoreV2}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1275\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1276\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1277\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key beta1_power_1 not found in checkpoint\n\t [[node save_6/RestoreV2 (defined at <ipython-input-18-009371bbf2b9>:78) ]]\n\t [[node save_6/RestoreV2 (defined at <ipython-input-18-009371bbf2b9>:78) ]]\n\nCaused by op 'save_6/RestoreV2', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/jason/.local/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/jason/.local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/jason/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/jason/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/jason/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/jason/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/jason/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/jason/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/jason/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/jason/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/home/jason/.local/lib/python3.5/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/jason/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/jason/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/jason/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-a0f366644799>\", line 4, in <module>\n    vae.restore(\"./model/model.ckpt\", sess)\n  File \"<ipython-input-18-009371bbf2b9>\", line 78, in restore\n    saver = tf.train.Saver()\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n    self.build()\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 844, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 881, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 332, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 580, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1572, in restore_v2\n    name=name)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Key beta1_power_1 not found in checkpoint\n\t [[node save_6/RestoreV2 (defined at <ipython-input-18-009371bbf2b9>:78) ]]\n\t [[node save_6/RestoreV2 (defined at <ipython-input-18-009371bbf2b9>:78) ]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1285\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1286\u001b[0;31m         \u001b[0mnames_to_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_graph_key_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mobject_graph_key_mapping\u001b[0;34m(checkpoint_path)\u001b[0m\n\u001b[1;32m   1590\u001b[0m   object_graph_string = reader.get_tensor(\n\u001b[0;32m-> 1591\u001b[0;31m       checkpointable.OBJECT_GRAPH_PROTO_KEY)\n\u001b[0m\u001b[1;32m   1592\u001b[0m   object_graph_proto = (\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(self, tensor_str)\u001b[0m\n\u001b[1;32m    369\u001b[0m         return CheckpointReader_GetTensor(self, compat.as_bytes(tensor_str),\n\u001b[0;32m--> 370\u001b[0;31m                                           status)\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a0f366644799>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnb_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./model/model.ckpt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlatent_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_latent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-009371bbf2b9>\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, ckpt_file, sess)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1290\u001b[0m         \u001b[0;31m# a helpful message (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m         raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1292\u001b[0;31m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0m\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0;31m# This is an object-based checkpoint. We'll print a warning and then do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey beta1_power_1 not found in checkpoint\n\t [[node save_6/RestoreV2 (defined at <ipython-input-18-009371bbf2b9>:78) ]]\n\t [[node save_6/RestoreV2 (defined at <ipython-input-18-009371bbf2b9>:78) ]]\n\nCaused by op 'save_6/RestoreV2', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/jason/.local/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/jason/.local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/jason/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/jason/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/jason/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/jason/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/jason/.local/lib/python3.5/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/jason/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/jason/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/jason/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/jason/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/home/jason/.local/lib/python3.5/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/jason/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/jason/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/jason/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-a0f366644799>\", line 4, in <module>\n    vae.restore(\"./model/model.ckpt\", sess)\n  File \"<ipython-input-18-009371bbf2b9>\", line 78, in restore\n    saver = tf.train.Saver()\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n    self.build()\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 844, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 881, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 332, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 580, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1572, in restore_v2\n    name=name)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/jason/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey beta1_power_1 not found in checkpoint\n\t [[node save_6/RestoreV2 (defined at <ipython-input-18-009371bbf2b9>:78) ]]\n\t [[node save_6/RestoreV2 (defined at <ipython-input-18-009371bbf2b9>:78) ]]\n"
     ]
    }
   ],
   "source": [
    "# Random spampling from latent space\n",
    "nb_samples = 64\n",
    "with tf.Session() as sess:\n",
    "    vae.restore(\"./model/model.ckpt\", sess)\n",
    "    latent_samples = np.random.randn(nb_samples, dim_latent)\n",
    "\n",
    "    generated_images = sess.run(vae.reconstruction,\n",
    "                                feed_dict={vae.latent_vec: latent_samples})\n",
    "\n",
    "    print(np.squeeze(generated_images[0]))\n",
    "\n",
    "    for im in generated_images:\n",
    "        plt.figure()\n",
    "        plt.imshow(np.squeeze(im), vmin=0, vmax=1)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
